
import scrapy
from tutorial.items import TencentItem
from scrapy.linkextractors import LinkExtractor
from scrapy.spiders import CrawlSpider,Rule
import json
import codecs
class TencentSpider(CrawlSpider):
    #filename = codecs.open('tencent_data.json', mode='wb', encoding='utf-8')
    name = "tencent"
    allowed_domains = ["bbs.tianya.cn"]

    start_urls =["http://bbs.tianya.cn/post-free-2052991-1.shtml"]

    #rules=(
    #        Rule(LinkExtractor(allow=(r"/a/20\d",)),callback="parse_item",follow=True),
    #        Rule(LinkExtractor(allow=r"",deny=('m\.','/iask/','/z/','weibo','snapshot','cn/c/2','cn/w/1','/world/99','hi','richtalk','question','auto','baoxian','opinion','roll','club','comment','wp','survey','slide','tag','blog','video','house','bbs','club','app','photo','game','live','vip',)),follow=True),
    #)

    def parse_item(self, response):      
        item = TencentItem()
        item['platform'] = "tencent"
        item['tid']=response.url.strip().split('/')[-1][:-4]
        self.getTitle(response,item)
        item['url'] = response.url
        self.getCate(response,item)
        self.getNews(response,item)
        self.getAuthor(response,item)
        self.getTime(response,item)
        self.getDesc(response,item)
        if 'desc' in item:
            #line = json.dumps(dict(item)) + '\n'
            #self.filename.write(line.decode("unicode_escape"))
            return item
